
import React, { useEffect, useRef, useState, useCallback } from 'react';
import Webcam from 'react-webcam';
import * as tf from '@tensorflow/tfjs';
import * as handpose from '@tensorflow-models/handpose';

interface GestureControllerProps {
  onGesture: (data: { isOpen: boolean; position: { x: number; y: number }, isDetected: boolean }) => void;
  isGuiVisible: boolean;
}

const GestureController: React.FC<GestureControllerProps> = ({ onGesture, isGuiVisible }) => {
  const webcamRef = useRef<Webcam>(null);
  const [model, setModel] = useState<handpose.HandPose | null>(null);
  const [loading, setLoading] = useState(true);
  const [cameraError, setCameraError] = useState(false);
  const [debugState, setDebugState] = useState<string>("-");
  const [loadingMessage, setLoadingMessage] = useState("Initializing AI Engine...");
  
  const onGestureRef = useRef(onGesture);
  useEffect(() => {
    onGestureRef.current = onGesture;
  }, [onGesture]);

  const lastDetectionTime = useRef(0);
  const ratioHistory = useRef<number[]>([]);
  const posHistory = useRef<{x:number, y:number}[]>([]);
  const isCurrentlyOpen = useRef<boolean>(false);
  const missedFrames = useRef(0);

  useEffect(() => {
    let isMounted = true;
    
    const loadModel = async () => {
      try {
        setLoadingMessage("Connecting to GPU...");
        // FIX: Cast tf to any because the 'ready' method might be missing from the specific type definition file in some environments.
        await (tf as any).ready();
        if (isMounted) setLoadingMessage("Loading Local AI Model...");
        
        // ä¿®æ­£ï¼šåœ¨æž„å»ºåŽçš„é¡¹ç›®ä¸­ï¼Œèµ„æºè·¯å¾„åº”ç›´æŽ¥æŒ‡å‘æ ¹ç›®å½•
        const LOCAL_MODEL_URL = '/models/handpose/model.json';

        const net = await handpose.load({
            modelUrl: LOCAL_MODEL_URL
        } as any);
        
        if (isMounted) {
          setModel(net);
          setLoading(false);
        }
      } catch (err) {
        console.error("Failed to load handpose model:", err);
        if (isMounted) setLoadingMessage("AI initialization failed");
      }
    };

    loadModel();
    return () => { isMounted = false; };
  }, []);

  const runDetection = useCallback(async () => {
    if (model && webcamRef.current && webcamRef.current.video && webcamRef.current.video.readyState === 4) {
      const now = Date.now();
      if (now - lastDetectionTime.current < 100) {
        requestAnimationFrame(runDetection);
        return;
      }
      lastDetectionTime.current = now;

      const video = webcamRef.current.video;
      if (video.videoWidth === 0) {
          requestAnimationFrame(runDetection);
          return;
      }

      try {
        const predictions = await model.estimateHands(video);

        if (predictions.length > 0) {
          missedFrames.current = 0;
          const hand = predictions[0];
          const landmarks = hand.landmarks;
          const wrist = landmarks[0];

          const rawX = -1 * ((wrist[0] / video.videoWidth) * 2 - 1); 
          const rawY = -1 * ((wrist[1] / video.videoHeight) * 2 - 1);
          
          posHistory.current.push({x: rawX, y: rawY});
          if (posHistory.current.length > 8) posHistory.current.shift(); 

          const avgPos = posHistory.current.reduce((acc, curr) => ({ x: acc.x + curr.x, y: acc.y + curr.y }), {x:0, y:0});
          const x = avgPos.x / posHistory.current.length;
          const y = avgPos.y / posHistory.current.length;

          const tips = [8, 12, 16, 20], bases = [5, 9, 13, 17];
          const getDist = (p1: number[], p2: number[]) => Math.sqrt(Math.pow(p1[0]-p2[0], 2) + Math.pow(p1[1]-p2[1], 2));

          let totalBaseDist = 0, totalTipDist = 0;
          for(let i=0; i<4; i++) {
              totalBaseDist += getDist(wrist, landmarks[bases[i]]);
              totalTipDist += getDist(wrist, landmarks[tips[i]]);
          }

          const rawRatio = totalTipDist / (totalBaseDist || 1);
          ratioHistory.current.push(rawRatio);
          if (ratioHistory.current.length > 5) ratioHistory.current.shift();
          const smoothedRatio = ratioHistory.current.reduce((a,b) => a+b, 0) / ratioHistory.current.length;

          if (!isCurrentlyOpen.current && smoothedRatio > 1.6) isCurrentlyOpen.current = true;
          else if (isCurrentlyOpen.current && smoothedRatio < 1.2) isCurrentlyOpen.current = false;

          setDebugState(isCurrentlyOpen.current ? `OPEN` : `CLOSED`);
          onGestureRef.current({ isOpen: isCurrentlyOpen.current, position: { x, y }, isDetected: true });
        } else {
          missedFrames.current++;
          if (missedFrames.current > 5) {
              isCurrentlyOpen.current = false; 
              setDebugState("NO HAND");
              onGestureRef.current({ isOpen: false, position: {x:0, y:0}, isDetected: false });
          }
        }
      } catch (err) {}
    }
    requestAnimationFrame(runDetection);
  }, [model]);

  useEffect(() => {
    if (model && !loading) {
      const timer = requestAnimationFrame(runDetection);
      return () => cancelAnimationFrame(timer);
    }
  }, [model, loading, runDetection]);

  const boxStyle = "w-28 h-36 md:w-48 md:h-36 rounded-lg border-[#d4af37]/50 bg-black/90 border overflow-hidden shadow-[0_0_20px_rgba(212,175,55,0.2)]";

  return (
    <div className={`fixed bottom-4 right-4 z-50 transition-all duration-500 ${isGuiVisible ? 'opacity-100 translate-y-0' : 'opacity-0 translate-y-10 pointer-events-none'}`}>
      <div className={`relative ${boxStyle}`}>
          {cameraError ? (
             <div className="flex flex-col items-center justify-center h-full text-[#d4af37] p-2 text-center">
                <span className="text-xl">ðŸ“·</span>
                <span className="text-[10px] font-luxury uppercase">Camera Unavailable</span>
             </div>
          ) : (
            <>
                <Webcam ref={webcamRef} mirrored={true} videoConstraints={{ facingMode: "user" }} className={`w-full h-full object-cover ${loading ? 'opacity-20' : 'opacity-80'}`} onUserMediaError={() => setCameraError(true)} />
                {!loading && <div className="absolute inset-0 bg-gradient-to-b from-transparent via-[#d4af37]/10 to-transparent animate-scan pointer-events-none" />}
            </>
          )}
          {loading && !cameraError && (
              <div className="absolute inset-0 flex flex-col items-center justify-center text-[#d4af37] p-4 bg-black/80 backdrop-blur-sm">
                  <div className="w-5 h-5 border-2 border-[#d4af37] border-t-transparent rounded-full animate-spin mb-2"></div>
                  <span className="text-[9px] font-luxury uppercase text-center animate-pulse">{loadingMessage}</span>
              </div>
          )}
          <div className="absolute bottom-0 left-0 right-0 bg-gradient-to-t from-black via-black/90 to-transparent p-2 flex justify-between items-end">
            <span className="text-[8px] text-[#d4af37]/80 font-luxury tracking-widest uppercase">Sensors</span>
            <span className={`text-[10px] font-mono font-bold ${debugState.includes("OPEN") ? "text-white drop-shadow-[0_0_5px_rgba(255,255,255,0.8)]" : "text-[#d4af37]"}`}>
                {debugState}
            </span>
          </div>
      </div>
      <style>{`@keyframes scan {0% { transform: translateY(-100%); } 100% { transform: translateY(100%); } } .animate-scan { animation: scan 3s linear infinite; }`}</style>
    </div>
  );
};

export default GestureController;
